{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_two_columns(campaign_id, listing_id_partner_id):\n",
    "    if campaign_id == None:\n",
    "        return '0-' + str(listing_id_partner_id)\n",
    "    else:\n",
    "        return str(campaign_id) + '-0-0'\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Public modules\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import networkx as nx\n",
    "import pyperclip as clip\n",
    "from numpy.random import seed\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler    \n",
    "\n",
    "project_path = os.path.abspath('')\n",
    "df1 = pd.read_csv(f\"{project_path}/data_raw/group1.csv\")\n",
    "df2 = pd.read_csv(f\"{project_path}/data_raw/group2.csv\")\n",
    "df1['listing_id_partner_id'] = None\n",
    "df2['campaign_id'] = None\n",
    "df1 = df1[['campaign_id', 'listing_id_partner_id', 'description']]\n",
    "df2 = df2[['campaign_id', 'listing_id_partner_id', 'description']]\n",
    "df = pd.concat([df1,df2], axis=0)\n",
    "df.to_csv(\"data_temp/df.csv\")\n",
    "df['description_length'] = df['description'].apply(lambda x: len(str(x)))\n",
    "df = df.loc[df['description_length'] >= 4]\n",
    "df['id'] = df[['campaign_id', 'listing_id_partner_id']].apply(lambda x: combine_two_columns(*x), axis=1)\n",
    "df = df.sample(200)\n",
    "df.drop(['campaign_id', 'listing_id_partner_id', 'description_length'], axis=1, inplace=True)\n",
    "df = df[['id', 'description']]\n",
    "df.set_index(['id'], inplace=True)\n",
    "paragraphs = df.description.values\n",
    "print(df1.shape, df2.shape, df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import InferSent\n",
    "\n",
    "#### Load Facebook's InferSent (download the files from the internet)\n",
    "infersent = InferSent({'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': 1})\n",
    "infersent.load_state_dict(torch.load('/Users/petermyers/Desktop/Other/data/InferSent/encoder/infersent1.pkl'))\n",
    "infersent.set_w2v_path('/Users/petermyers/Desktop/Other/data/GloVe/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infersent.build_vocab(paragraphs, tokenize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = infersent.encode(paragraphs, tokenize=True, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pdist(np.array(embeddings), metric='euclidean')\n",
    "paragraph_similarity_matrix = squareform(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(paragraph_similarity_matrix)\n",
    "temp = pd.DataFrame()\n",
    "for col in result.columns:\n",
    "    temp[col] = pd.to_numeric(result[col], downcast='float')\n",
    "result = temp\n",
    "result.columns = df.index\n",
    "result.index = df.index\n",
    "result.reset_index(inplace=True)\n",
    "result = pd.melt(result, id_vars=[\"id\"],\n",
    "                                var_name=\"id2\",\n",
    "                                value_name=\"score\").\\\n",
    "                                sort_values(by=\"score\", ascending=True)\n",
    "result.rename(columns={\"id\": \"id1\"}, inplace=True)\n",
    "result = result.join(df, on='id1', how='left')\n",
    "result.rename(columns={\"description\": \"description1\"}, inplace=True)\n",
    "result = result.join(df, on='id2', how='left')\n",
    "result.rename(columns={\"description\": \"description2\"}, inplace=True)\n",
    "result = result.loc[result['id1'] != result['id2']]\n",
    "result = result.loc[~result['id1'].str.startswith('0-')]\n",
    "result = result.loc[result['id2'].str.startswith('0-')]\n",
    "print(result.shape)\n",
    "result.to_csv(\"data_output/result.csv\")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "commons3",
   "language": "python",
   "name": "commons3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
